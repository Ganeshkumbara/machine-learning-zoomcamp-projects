{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "544affa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d12ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = \"salary_model.pkl\"\n",
    "\n",
    "def load_model(path: str = None):\n",
    "    with open(path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    return model\n",
    "\n",
    "model_package = load_model(MODEL_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f47bee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_package['model']\n",
    "dv = model_package['dict_vectorizer']\n",
    "# numerical_features = model_package['numberical_features']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f472c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('salary_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREDICTION PIPELINE - Using DictVectorizer for ALL features\n",
      "================================================================================\n",
      "\n",
      "1. Normalizing dataframe (lowercase, underscores)...\n",
      "   ✓ Normalized 33 columns\n",
      "\n",
      "2. DictVectorizer info:\n",
      "   Total encoded features: 114\n",
      "   Numerical features: ['python_yn', 'spark', 'aws', 'num_comp', 'desc_len', 'employer_provided', 'excel', 'hourly']\n",
      "\n",
      "3. Required columns from training (count=15):\n",
      "   ['aws', 'desc_len', 'employer_provided', 'excel', 'hourly', 'job_simp', 'job_state', 'num_comp', 'python_yn', 'revenue', 'sector', 'seniority', 'size', 'spark', 'type_of_ownership']\n",
      "\n",
      "   ✓ All required columns present in dataframe\n",
      "\n",
      "4. Handling missing values...\n",
      "\n",
      "5. Converting to dictionary format...\n",
      "   ✓ Created 742 dictionaries\n",
      "   Sample dict keys: ['aws', 'desc_len', 'employer_provided', 'excel', 'hourly', 'job_simp', 'job_state', 'num_comp', 'python_yn', 'revenue', 'sector', 'seniority', 'size', 'spark', 'type_of_ownership']\n",
      "\n",
      "6. Applying DictVectorizer transformation...\n",
      "   ✓ Transformed shape: (742, 114)\n",
      "   Total features: 114\n",
      "\n",
      "7. Feature count validation:\n",
      "   Model expects: 114 features\n",
      "   X has: 114 features\n",
      "   ✓ Feature count MATCHES!\n",
      "\n",
      "8. Making predictions...\n",
      "   ✓ Predictions successful!\n",
      "   Min: $17.47k\n",
      "   Max: $243.89k\n",
      "   Mean: $100.61k\n",
      "   Median: $97.20k\n",
      "\n",
      "   ✓ Results saved to: salary_predictions.csv\n",
      "\n",
      "9. Sample predictions (first 5 rows):\n",
      " Actual  Predicted      Error\n",
      "   72.0  83.982092 -11.982092\n",
      "   87.5  95.427226  -7.927226\n",
      "   85.0  88.595496  -3.595496\n",
      "   76.5  80.589403  -4.089403\n",
      "  114.5 104.355441  10.144559\n",
      "\n",
      "================================================================================\n",
      "✓ PREDICTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create X dataset for prediction\n",
    "import numpy as np\n",
    "\n",
    "# Normalize dataframe to match training preprocessing\n",
    "df_norm = df.copy()\n",
    "df_norm.columns = df_norm.columns.str.lower().str.replace(' ', '_')\n",
    "for col in df_norm.select_dtypes(include=['object']).columns:\n",
    "    df_norm[col] = df_norm[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Extract required features from DictVectorizer\n",
    "dv_feature_names = dv.get_feature_names_out()\n",
    "all_training_cols = sorted({f.split('=')[0] for f in dv_feature_names})\n",
    "\n",
    "# Check for missing columns\n",
    "missing_cols = [c for c in all_training_cols if c not in df_norm.columns]\n",
    "if missing_cols:\n",
    "    print(f\"⚠️  WARNING: Missing columns: {missing_cols}\")\n",
    "\n",
    "# Select columns used in training\n",
    "df_features = df_norm[all_training_cols].copy()\n",
    "\n",
    "# Handle missing values\n",
    "for col in df_features.columns:\n",
    "    if df_features[col].isnull().sum() > 0:\n",
    "        if df_features[col].dtype == 'object':\n",
    "            df_features[col] = df_features[col].fillna('missing')\n",
    "        else:\n",
    "            df_features[col] = df_features[col].fillna(0)\n",
    "\n",
    "# Convert to dictionary format for DictVectorizer\n",
    "feature_dicts = df_features.to_dict('records')\n",
    "\n",
    "# Transform using DictVectorizer\n",
    "X = dv.transform(feature_dicts)\n",
    "\n",
    "# Verify feature count matches model\n",
    "expected_total = model.n_features_in_\n",
    "if X.shape[1] != expected_total:\n",
    "    print(f\"⚠️  Feature mismatch! Expected: {expected_total}, Got: {X.shape[1]}\")\n",
    "\n",
    "# Make predictions\n",
    "try:\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    print(f\"Predictions successful!\")\n",
    "    print(f\"  Min: ${predictions.min():.2f}k\")\n",
    "    print(f\"  Max: ${predictions.max():.2f}k\")\n",
    "    print(f\"  Mean: ${predictions.mean():.2f}k\")\n",
    "    print(f\"  Median: ${np.median(predictions):.2f}k\")\n",
    "    \n",
    "    # Add predictions to original dataframe\n",
    "    df['predicted_salary'] = predictions\n",
    "    \n",
    "    # Save results\n",
    "    output_file = 'salary_predictions.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Results saved to: {output_file}\")\n",
    "    \n",
    "    # Show sample comparison if actual salary available\n",
    "    if 'avg_salary' in df.columns:\n",
    "        print(f\"\\nSample predictions (first 5 rows):\")\n",
    "        comparison = pd.DataFrame({\n",
    "            'Actual': df['avg_salary'].head(),\n",
    "            'Predicted': predictions[:5],\n",
    "            'Error': df['avg_salary'].head() - predictions[:5]\n",
    "        })\n",
    "        print(comparison.to_string(index=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Prediction failed: {str(e)}\")\n",
    "\n",
    "# For downstream single-row predictions\n",
    "Y = df.get('avg_salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single sample prediction for row #192...\n",
      "\n",
      "✓ Prediction Made:\n",
      "  Predicted Salary: $131.78k\n",
      "\n",
      "✓ Comparison:\n",
      "  Actual:    $134.50k\n",
      "  Predicted: $131.78k\n",
      "  Error:     $2.72k (+2.03%)\n",
      "  Quality:   ✓ EXCELLENT (<10% error)\n"
     ]
    }
   ],
   "source": [
    "# Single sample prediction test\n",
    "sample_index = 192\n",
    "\n",
    "X_single = X[sample_index:sample_index+1]\n",
    "y_actual = Y.iloc[sample_index] if Y is not None else None\n",
    "\n",
    "y_prediction = model.predict(X_single)[0]\n",
    "\n",
    "print(f\"Sample #{sample_index}:\")\n",
    "print(f\"  Predicted Salary: ${y_prediction:.2f}k\")\n",
    "\n",
    "if y_actual is not None:\n",
    "    error_dollars = y_actual - y_prediction\n",
    "    error_percent = (error_dollars / y_actual) * 100\n",
    "    \n",
    "    print(f\"  Actual:    ${y_actual:.2f}k\")\n",
    "    print(f\"  Error:     ${error_dollars:.2f}k ({error_percent:+.2f}%)\")\n",
    "    \n",
    "    if abs(error_percent) < 10:\n",
    "        quality = \"EXCELLENT\"\n",
    "    elif abs(error_percent) < 20:\n",
    "        quality = \"GOOD\"\n",
    "    elif abs(error_percent) < 30:\n",
    "        quality = \"ACCEPTABLE\"\n",
    "    else:\n",
    "        quality = \"POOR\"\n",
    "    \n",
    "    print(f\"  Quality:   {quality}\")\n",
    "else:\n",
    "    print(\"  (No actual salary available for comparison)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e4ce2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = {'python_yn': 1,\n",
    " 'spark': 0,\n",
    " 'aws': 1,\n",
    " 'num_comp': 3,\n",
    " 'desc_len': 3747,\n",
    " 'employer_provided': 0,\n",
    " 'excel': 1,\n",
    " 'hourly': 0,\n",
    " 'seniority': 'jr',\n",
    " 'job_state': 'tx',\n",
    " 'type_of_ownership': 'company_-_public',\n",
    " 'sector': 'real_estate',\n",
    " 'job_simp': 'data_scientist',\n",
    " 'revenue': '$1_to_$2_billion_(usd)',\n",
    " 'size': '201_to_500_employees'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9d611f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(dtype=<class 'int'>, sparse=False),\n",
       " RandomForestRegressor(max_depth=15, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=42))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51378cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_x = dv.transform([customer_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d4698cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112.82678698])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(customer_x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54490064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlzc (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
